# Multi-Process and Multi-Threading of Python

## 1. Introduction

This lab talk about how to write the multi-process / multi-threading / thread pool code of Python, as well as the concept of threadlocal.  A process or thread can only handle one task at a time. In order to improve the efficiency of program execution, sometimes we need to open multiple processes or threads. Python provides `threading` and` multiprocessing` modules to facilitate writing multi-threading code.

### Learning Objective

- Development of multi-process program in Python3 
- Interprocess communication
- Process synchronization
- Pool
- Multithreaded program in Python 3
- The concept of GIL

##2. Content

###2.1 Multi-processes

The` Process` class under the `multiprocessing` encapsulates the multi-process operation. Let's see how it is used through a multi-process program :

```py
import os
from multiprocessing import Process

def hello(name):
    print('child process: {}'.format(os.getpid()))
    print('Hello ' + name)

def main():
	 # Note: The args parameter should be passed in tuple
    p = Process(target=hello, args=('labex', ))
    p.start()
    p.join()
    print('parent process: {}'.format(os.getpid()))

if __name__ == '__main__':
    main()
```


![image desc](https://labex.io/upload/K/D/W/iEip6UqnBxI3.png)


In the above procedure, first import `Process` class from the `multiprocessing`, and then define a `hello` function.Next to print 'hello' and name value.In the `main` function, use `Process` class to define a subprocess that is going to perform the 'hello' function.The incoming parameter is `labex`, and then call the` start () `method, and the subprocess will call the `hello` function, passing 'labex' as parameter, print the current Process id and 'hello labex' after the return. The `join ()` method means that the subprocess continues to run after the waiting process is finished, so the parent process's id will continue to be printed after the subprocess returns.

The output will be like this when you run the program:

```
child process: 60901                                                                                                  
Hello labex                                                                                                       
parent process: 60900
```

The process id varies each time you run the program.

###2.2 Internal Communication

The process has its own independent operating space, which means that it requires some special ways to achieve the data exchange between them. The `multiprocessing` module provides` Pipe` and `Queue` to achieve it.

####2.2.1 Pipe

If you imagine that two processes as two sealed boxes, then the pipe is like a channel connecting two boxes, and it can be used to exchange simple data.Look at its use:

```py
from multiprocessing import Pipe

conn1, conn2 = Pipe()
```

Pipe () returns a tuple containing two joins. By default, the open pipe is full duplex, that is, you can read and write data in any section. Data-writing uses the `send` method, data-reading uses the` recv` method. Here's an example:

```py
from multiprocessing import Process, Pipe

conn1, conn2 = Pipe()

def f1():
    conn1.send('Hello labex')

def f2():
    data = conn2.recv()
    print(data)

def main():
    Process(target=f1).start()
    Process(target=f2).start()

if __name__ == '__main__':
    main()
```

This procedure starts two processes. The first process in the f1 function writes `Hello labex` to the pipe, and the second process in the f2 function reads and prints data from the pipeline.


![image desc](https://labex.io/upload/K/A/N/ovpiXoETXiEP.png)

####2.2.2 Queue

In addition to Pipe, the `multiprocessing` module also implements a queue structure 'Queue' that can be realized in a multi-process to override the program above:

```py
from multiprocessing import Process, Queue

queue = Queue()

def f1():
    queue.put('Hello labex')

def f2():
    data = queue.get()
    print(data)

def main():
    Process(target=f1).start()
    Process(target=f2).start()

if __name__ == '__main__':
    main()

```


![image desc](https://labex.io/upload/F/K/X/2xP8NSpLbCOs.png)


Queue can specify a maximum capacity at initialization:

```py
queue = Queue(maxsize=10)
```

###2.3 Process Synchronization

Look at an example, there is a counter i, the initial value is 0. Now we have 10 processes, each process does 50 times  `+1` operation to 'i', that is to say theoretically the final result is 500. Code:

```py
import time
from multiprocessing import Process, Value

def func(val):
    for i in range(50):
        time.sleep(0.01)
        val.value += 1

if __name__ == '__main__':
    # Multi-process can not use global variables.The value provided by multiprocessing is an agent,
	 # Can share this variable in the multi-process.
    v = Value('i', 0)
    procs = [Process(target=func, args=(v,)) for i in range(10)]

    for p in procs:
    	p.start()
    for p in procs:
    	p.join()

    print(v.value)

```


![image desc](https://labex.io/upload/B/X/P/Qj31QmljAP7a.png)


As the process of multi-process advance is unpredictable, it is likely to occur that several processes add 1 to i at the same time in the multi-core CPU, but the read and write mechanism in the memory and the CPU only record one process of plusing 1 , leading to the final result should be less than 500. The four-times operation result:  

```
498
500
497
498
```

The right way is to add a lock to i each time when you plus 1, that is, when it is handling i, the other process can not operate it. 'Lock' class operation in `multiprocessing` module uses `acquire()` to get the lock,and uses `release()` to remove the clock.Here is the modified code:

```py
import time
from multiprocessing import Process, Value, Lock

def func(val, lock):
    for i in range(50):
        time.sleep(0.01)
        # with lock sentence is a shorthand for the following statement:
        # get a lock
        # lock.acquire()
        # val.calue += 1
        # lock.release()
        # operation in lock
        with lock:
            val.value += 1

if __name__ == '__main__':
	 
    v = Value('i', 0)
    # init the lock
    lock = Lock()
    procs = [Process(target=func, args=(v, lock)) for i in range(10)]

    for p in procs:
    	p.start()
    for p in procs:
    	p.join()

    print(v.value)

```

Now the result is 500 every time.


![image desc](https://labex.io/upload/H/J/A/KschSOsvYY5x.png)

###2.4 Pool

Pool maintains a fixed number of the process.When the task comes, it goes to a process in the pool to deal with the task, and after processing, the process is returned to pool. If a task comes when the process in the pool is exhausted, the task needs to wait for a process to finish.

Use a pool to print 0 ~ 30:

```py
from multiprocessing import Pool

def f(i):
    print(i, end=' ')

def main():
	  # Initialize pool of three processes
    pool = Pool(processes=3)
    for i in range(30):
		   # Call the 'apply' method to start processing tasks, and income task to handle f and parameter i
        pool.apply(f, (i,))

if __name__ == '__main__':
    main()
```


![image desc](https://labex.io/upload/X/B/O/fa8sPN8qqakQ.png)

###2.5 Multithreading

Python's `threading` module provides support for multithreading. The interface and the multi-process interfaces provided by `multiprocessing` are very similar. Here is the example using multi-threading to override the multi-process:

```py
import threading

def hello(name):
	  # get_ident() function to acquire the current threading id
    print('child thread: {}'.format(threading.get_ident()))
    print('Hello ' + name)

def main():
    # Initialize a thread.Passing a parameter is similar to that of using Process.
    t = threading.Thread(target=hello, args=('labex',))
    # Start the thread and wait for the thread to end.This is the same as the interface of Process.
    t.start()
    t.join()
    print('main thread: {}'.format(threading.get_ident()))

if __name__ == '__main__':
    main()

```


![image desc](https://labex.io/upload/V/G/H/DDYBW4PYpd2F.png)

###2.6 GIL(Global Intergreter Lock)

GIL is a place where Python is often criticized. Python is an interpreted language, and it executes in this way:


```
*.py source code -> *.pyc bytecode -> Python interpreter interprets execution
```

Since Python's memory management is not thread-safe, Python implements a lock internally, allowing only one thread to use the Python interpreter at a time, which means that Python's multithreading is pseudo-multithreading and it does not do real concurrency.

This is an official explanation:

>  In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecode at once. This lock is necessary mainly because CPythonâ€™s memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.  

Because of the existence of GIL, Python's multithreading is actually running on the core of a CPU, that is, it can not take full advantage of the CPU's multi-core. So in actual use, we still recommend the use of multi-process.

##3. Summary


In this lab we have learned about Python's multi-process and multi-threaded programming. Learning to use the `multiprocessing` and` threading` modules to develop multi-process and multi-threaded programs.
